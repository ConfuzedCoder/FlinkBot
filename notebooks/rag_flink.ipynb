{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere.embeddings import CohereEmbeddings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dipak/FlinkBot/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/dipak/FlinkBot/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
    "model_kwargs = {'device': 'mps', \"trust_remote_code\": True}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MILVUS_URL = os.environ['MILVUS_URL']\n",
    "MILVUS_KEY = os.environ['MILVUS_KEY']\n",
    "DIMS = 1024\n",
    "EMBEDDING_MODEL = \"embed-english-v3.0\"\n",
    "COHERE_KEY=os.environ['COHERE_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_fn = CohereEmbeddings(model=EMBEDDING_MODEL, cohere_api_key=COHERE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = hf.embed_query(\"What is flink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://in03-a472fda6cef4f90.api.gcp-us-west1.zillizcloud.com'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MILVUS_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.zilliz import Zilliz\n",
    "\n",
    "zilliz = Zilliz(\n",
    "    embedding_function = hf,\n",
    "    collection_name=\"Flink\",\n",
    "    connection_args={\"uri\": MILVUS_URL, \"token\": MILVUS_KEY},\n",
    "    auto_id=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = zilliz.as_retriever(search_kwargs={\"k\": 25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='how to configure the relevant components. The size of those components always has to be between its maximum and minimum value, otherwise Flink startup will fail.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/memory/mem_setup/', 'type': 'document', 'pk': 450143955092274740}),\n",
       " Document(page_content='â\\x96¾ Monitoring Checkpointing Monitoring Back Pressure Upgrading Applications and Flink Versions Production Readiness Checklist Flink Development â\\x96¾ Importing Flink into an IDE Building Flink from Source Internals â\\x96¾ Jobs and Scheduling Task Lifecycle File Systems Project Homepage JavaDocs ScalaDocs PyDocs Pick Docs Version â\\x96¾ 1.16 (â\\x9c\\x93) v1.16 v1.15 All Versions ä¸\\xadæ\\x96\\x87ç\\x89\\x88 Elastic Scaling On This Page Reactive Mode Getting started Usage Limitations Adaptive Scheduler Usage Limitations Adaptive Batch Scheduler Usage Performance tuning Limitations Elastic Scaling # Apache Flink allows you to rescale your jobs. You can do this manually by stopping the job and restarting from the savepoint created during shutdown with a different parallelism. This page describes options where Flink automatically adjusts the parallelism instead. Reactive Mode # Reactive mode is an MVP (“minimum viable product”) feature. The Flink community is actively looking for feedback by users through our mailing', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/elastic_scaling/', 'type': 'document', 'pk': 450143955092275030}),\n",
       " Document(page_content='scheduling Tuning Checkpoints and Large State # This page gives a guide how to configure and tune applications that use large state. Overview # For Flink applications to run reliably at large scale, two conditions must be fulfilled: The application needs to be able to take checkpoints reliably The resources need to be sufficient catch up with the input data streams after a failure The first sections discuss how to get well performing checkpoints at scale.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/large_state_tuning/', 'type': 'document', 'pk': 450143955092273160}),\n",
       " Document(page_content='configuration ) { return this ; } } Capacity Planning # This section discusses how to decide how many resources should be used for a Flink job to run reliably.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/large_state_tuning/', 'type': 'document', 'pk': 450143955092273182}),\n",
       " Document(page_content='scheduler are also available with it. The Flink community is working on addressing these limitations. No support for the Elastic Scaling . The elastic scaling only supports slot requests without specified-resource at the moment. No support for task manager redundancy . The slotmanager.redundant-taskmanager-num is used to start redundant TaskManagers to speed up job recovery. This config option will not take effect in fine-grained resource management at the moment. No support for evenly spread out slot strategy . This strategy tries to spread out the slots evenly across all available TaskManagers. The strategy is not supported in the first version of fine-grained resource management and cluster.evenly-spread-out-slots will not take effect in it at the moment. Limited integration with Flinkâ\\x80\\x99s Web UI . Slots in fine-grained resource management can have different resource specs. The web UI only shows the slot number without its details at the moment. Limited integration with batch jobs', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/finegrained_resource/', 'type': 'document', 'pk': 450143955092275108}),\n",
       " Document(page_content='feature. The Flink community is actively looking for feedback by users through our mailing lists. Please check the limitations listed on this page. Reactive Mode configures a job so that it always uses all resources available in the cluster. Adding a TaskManager will scale up your job, removing resources will scale it down. Flink will manage the parallelism of the job, always setting it to the highest possible values. Reactive Mode restarts a job on a rescaling event, restoring it from the latest completed checkpoint. This means that there is no overhead of creating a savepoint (which is needed for manually rescaling a job). Also, the amount of data that is reprocessed after rescaling depends on the checkpointing interval, and the restore time depends on the state size. The Reactive Mode allows Flink users to implement a powerful autoscaling mechanism, by having an external service monitor certain metrics, such as consumer lag, aggregate CPU utilization, throughput or latency. As soon', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/elastic_scaling/', 'type': 'document', 'pk': 450143955092275032}),\n",
       " Document(page_content='Hence, you need to build a dedicated Flink Image per application.\\nPlease check here for the details.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/docker/', 'type': 'document', 'pk': 450143955092274072}),\n",
       " Document(page_content='without putting undue load on your sinks. How much load can your Task Managers sustain: All of Flinks’ built-in state backends support asynchronous checkpointing, meaning the snapshot process will not pause data processing. However, it still does require CPU cycles and network bandwidth from your machines. Incremental checkpointing can be a powerful tool to reduce the cost of any given checkpoint. And most importantly, test and measure your job. Every Flink application is unique, and the best way to find the appropriate checkpoint interval is to see how yours behaves in practice. Configure JobManager High Availability # The JobManager serves as a central coordinator for each Flink deployment, being responsible for both scheduling and resource management of the cluster.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/production_ready/', 'type': 'document', 'pk': 450143955092273914}),\n",
       " Document(page_content='In combination with Kubernetes, the replica count of the TaskManager deployment determines the available resources. Increasing the replica count will scale up the job, reducing it will trigger a scale down. This can also be done automatically by using a Horizontal Pod Autoscaler . To use Reactive Mode on Kubernetes, follow the same steps as for deploying a job using an Application Cluster . But instead of flink-configuration-configmap.yaml use this config map: flink-reactive-mode-configuration-configmap.yaml . It contains the scheduler-mode: reactive setting for Flink. Once you have deployed the Application Cluster , you can scale your job up or down by changing the replica count in the flink-taskmanager deployment. Enabling Local Recovery Across Pod Restarts # In order to speed up recoveries in case of pod failures, you can leverage Flink’s working directory feature together with local recovery.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/kubernetes/', 'type': 'document', 'pk': 450143955092274150}),\n",
       " Document(page_content='Flink on YARN Resource Allocation Behavior High-Availability on YARN Supported Hadoop versions. Running Flink on YARN behind Firewalls User jars & Classpath', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/yarn/', 'type': 'document', 'pk': 450143955092274312}),\n",
       " Document(page_content='While the Flink community has attempted to provide sensible defaults for each configuration, it is important to review this list and ensure the options chosen are sufficient for your needs. Set An Explicit Max Parallelism # The max parallelism, set on a per-job and per-operator granularity, determines the maximum parallelism to which a stateful operator can scale.\\nThere is currently no way to change the maximum parallelism of an operator after a job has started without discarding that operators state.\\nThe reason maximum parallelism exists, versus allowing stateful operators to be infinitely scalable, is that it has some impact on your application’s performance and state size.\\nFlink has to maintain specific metadata for its ability to rescale state which grows linearly with max parallelism.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/production_ready/', 'type': 'document', 'pk': 450143955092273906}),\n",
       " Document(page_content='While the community strives to offer sensible defaults to all configurations, the full breadth of applications\\nthat users deploy on Flink means this isn’t always possible. To provide the most production value to our users,\\nFlink allows both high-level and fine-grained tuning of memory allocation within clusters. To optimize memory requirements, check the network memory tuning guide . The further described memory configuration is applicable starting with the release version 1.10 for TaskManager and 1.11 for JobManager processes. If you upgrade Flink from earlier versions, check the migration guide because many changes were introduced with the 1.10 and 1.11 releases. Configure Total Memory # The total process memory of Flink JVM processes consists of memory consumed by the Flink application ( total Flink memory )', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/memory/mem_setup/', 'type': 'document', 'pk': 450143955092274728}),\n",
       " Document(page_content='if the metric fetcher causes too much load. Setting this value to 0 disables the metric fetching completely. metrics.internal.query-service.port \"0\" String The port range used for Flink\\'s internal metric query service. Accepts a list of ports (â\\x80\\x9c50100,50101â\\x80\\x9d), ranges(â\\x80\\x9c50100-50200â\\x80\\x9d) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple Flink components are running on the same machine. Per default Flink will pick a random port. metrics.internal.query-service.thread-priority 1 Integer The thread priority used for Flink\\'s internal metric query service. The thread is created by Akka\\'s thread pool executor. The range of the priority is from 1 (MIN_PRIORITY) to 10 (MAX_PRIORITY). Warning, increasing this value may bring the main Flink components down. metrics.job.status.enable CURRENT_TIME List<Enum> The selection of job status metrics that should be reported. Possible values: \"STATE\": For a given state, return 1 if the job is currently', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/config/', 'type': 'document', 'pk': 450143955092274468}),\n",
       " Document(page_content='},\\n          \"id\" : {\\n            \"type\" : \"any\"\\n          },\\n          \"maxParallelism\" : {\\n            \"type\" : \"integer\"\\n          },\\n          \"metrics\" : {\\n            \"type\" : \"object\",\\n            \"id\" : \"urn:jsonschema:org:apache:flink:runtime:rest:messages:job:metrics:IOMetricsInfo\",\\n            \"properties\" : {\\n              \"accumulated-backpressured-time\" : {\\n                \"type\" : \"integer\"\\n              },\\n              \"accumulated-busy-time\" : {\\n                \"type\" : \"number\"\\n              },\\n              \"accumulated-idle-time\" : {\\n                \"type\" : \"integer\"\\n              },\\n              \"read-bytes\" : {\\n                \"type\" : \"integer\"\\n              },\\n              \"read-bytes-complete\" : {\\n                \"type\" : \"boolean\"\\n              },\\n              \"read-records\" : {\\n                \"type\" : \"integer\"\\n              },\\n              \"read-records-complete\" : {\\n                \"type\" : \"boolean\"\\n              },', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092273470}),\n",
       " Document(page_content='Other components can be tuned using multiple options. Framework Memory # You should not change the framework heap memory and framework off-heap memory without a good reason.\\nAdjust them only if you are sure that Flink needs more memory for some internal data structures or operations.\\nIt can be related to a particular deployment environment or job structure, like high parallelism.\\nIn addition, Flink dependencies, such as Hadoop may consume more direct or native memory in certain setups. Note Flink neither isolates heap nor off-heap versions of framework and task memory at the moment.\\nThe separation of framework and task memory can be used in future releases for further optimizations. Local Execution # If you start Flink locally on your machine as a single java program without creating a cluster (e.g. from your IDE)', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/memory/mem_setup_tm/', 'type': 'document', 'pk': 450143955092274780}),\n",
       " Document(page_content='since the per-buffer overhead are significantly higher then per-record overheads in the Flink’s runtime. As a rule of thumb, we don’t recommend thinking about increasing the buffer size, or the buffer timeout unless you can observe a network bottleneck in your real life workload\\n(downstream operator idling, upstream backpressured, output buffer queue is full, downstream input queue is empty). If the buffer size is too large, this can lead to: high memory usage huge checkpoint data (for unaligned checkpoints) long checkpoint time (for aligned checkpoints) inefficient use of allocated memory with a small execution.buffer-timeout because flushed buffers would only be sent partially filled Selecting the buffer count # The number of buffers is configured by the taskmanager.network.memory.buffers-per-channel and taskmanager.network.memory.floating-buffers-per-gate settings. For best throughput, we recommend using the default values for the number of exclusive', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/memory/network_mem_tuning/', 'type': 'document', 'pk': 450143955092274940}),\n",
       " Document(page_content='certain metrics, such as consumer lag, aggregate CPU utilization, throughput or latency. As soon as these metrics are above or below a certain threshold, additional TaskManagers can be added or removed from the Flink cluster. This could be implemented through changing the replica factor of a Kubernetes deployment, or an autoscaling group on AWS. This external service only needs to handle the resource allocation and deallocation. Flink will take care of keeping the job running with the resources available. Getting started # If you just want to try out Reactive Mode, follow these instructions. They assume that you are deploying Flink on a single machine. # these instructions assume you are in the root directory of a Flink distribution. # Put Job into lib/ directory cp ./examples/streaming/TopSpeedWindowing.jar lib/ # Submit Job in Reactive Mode ./bin/standalone-job.sh start -Dscheduler-mode = reactive -Dexecution.checkpointing.interval = \"10s\" -j', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/elastic_scaling/', 'type': 'document', 'pk': 450143955092275034}),\n",
       " Document(page_content='JobManager Options # Key Default Type Description jobmanager.future-pool.size (none) Integer The size of the future thread pool to execute future callbacks for all spawned JobMasters. If no value is specified, then Flink defaults to the number of available CPU cores. jobmanager.io-pool.size (none) Integer The size of the IO thread pool to run blocking operations for all spawned JobMasters. This includes recovery and completion of checkpoints. Increase this value if you experience slow checkpoint operations when running many jobs. If no value is specified, then Flink defaults to the number of available CPU cores. Advanced Scheduling Options # These parameters can help with fine-tuning scheduling for specific situations. Key Default Type Description cluster.evenly-spread-out-slots false Boolean Enable the slot spread out allocation strategy. This strategy tries to spread out the slots evenly across all available TaskExecutors . cluster.fine-grained-resource-management.enabled false', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/config/', 'type': 'document', 'pk': 450143955092274596}),\n",
       " Document(page_content='}\\n          }\\n        },\\n        \"checkpointed_size\" : {\\n          \"type\" : \"object\",\\n          \"id\" : \"urn:jsonschema:org:apache:flink:runtime:rest:messages:checkpoints:StatsSummaryDto\",\\n          \"properties\" : {\\n            \"avg\" : {\\n              \"type\" : \"integer\"\\n            },\\n            \"max\" : {\\n              \"type\" : \"integer\"\\n            },\\n            \"min\" : {\\n              \"type\" : \"integer\"\\n            },\\n            \"p50\" : {\\n              \"type\" : \"number\"\\n            },\\n            \"p90\" : {\\n              \"type\" : \"number\"\\n            },\\n            \"p95\" : {\\n              \"type\" : \"number\"\\n            },\\n            \"p99\" : {\\n              \"type\" : \"number\"\\n            },\\n            \"p999\" : {\\n              \"type\" : \"number\"\\n            }\\n          }\\n        },\\n        \"end_to_end_duration\" : {\\n          \"type\" : \"object\",\\n          \"$ref\" : \"urn:jsonschema:org:apache:flink:runtime:rest:messages:checkpoints:StatsSummaryDto\"\\n        },', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092273518}),\n",
       " Document(page_content='Application Profiling & Debugging Monitoring â\\x96¾ Monitoring Checkpointing Monitoring Back Pressure Upgrading Applications and Flink Versions Production Readiness Checklist Flink Development â\\x96¾ Importing Flink into an IDE Building Flink from Source Internals â\\x96¾ Jobs and Scheduling Task Lifecycle File Systems Project Homepage JavaDocs ScalaDocs PyDocs Pick Docs Version â\\x96¾ 1.16 (â\\x9c\\x93) v1.16 v1.15 All Versions ä¸\\xadæ\\x96\\x87ç\\x89\\x88 Fine-Grained Resource Management On This Page Applicable Scenarios How it works Usage Enable Fine-Grained Resource Management Specify Resource Requirement for Slot Sharing Group Limitations Notice Deep Dive How it improves resource efficiency Resource Allocation Strategy Fine-Grained Resource Management # Apache Flink works hard to auto-derive sensible default resource requirements for all applications out of the box.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/finegrained_resource/', 'type': 'document', 'pk': 450143955092275082}),\n",
       " Document(page_content='Setting the environment variable MALLOC_ARENA_MAX can avoid unlimited memory growth: $ docker run \\\\ --env MALLOC_ARENA_MAX = 1 \\\\ flink:1.16.2-scala_2.12 <jobmanager | standalone-job | taskmanager> Further Customization # There are several ways in which you can further customize the Flink image: install custom software (e.g. python) enable (symlink) optional libraries or plugins from /opt/flink/opt into /opt/flink/lib or /opt/flink/plugins add other libraries to /opt/flink/lib (e.g. Hadoop) add other plugins to /opt/flink/plugins You can customize the Flink image in several ways: override the container entry point with a custom script where you can run any bootstrap actions.\\nAt the end you can call the standard /docker-entrypoint.sh script of the Flink image with the same arguments\\nas described in supported deployment modes . The following example creates a custom entry point script which enables more libraries and plugins.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/docker/', 'type': 'document', 'pk': 450143955092274098}),\n",
       " Document(page_content='Flink does not use Akka for data transport. Key Default Type Description akka.ask.callstack true Boolean If true, call stack for asynchronous asks are captured. That way, when an ask fails (for example times out), you get a proper exception, describing to the original method call and call site. Note that in case of having millions of concurrent RPC calls, this may add to the memory footprint. akka.ask.timeout 10 s Duration Timeout used for all futures and blocking Akka calls. If Flink fails due to timeouts then you should try to increase this value. Timeouts can be caused by slow machines or a congested network. The timeout value requires a time-unit specifier (ms/s/min/h/d). akka.client-socket-worker-pool.pool-size-factor 1.0 Double The pool size factor is used to determine thread pool size using the following formula: ceil(available processors * factor). Resulting size is then bounded by the pool-size-min and pool-size-max values. akka.client-socket-worker-pool.pool-size-max 2', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/config/', 'type': 'document', 'pk': 450143955092274690}),\n",
       " Document(page_content='parallelism when re-scaling the program (via a savepoint). Flink’s internal bookkeeping tracks parallel state in the granularity of max-parallelism-many key groups .\\nFlink’s design strives to make it efficient to have a very high value for the maximum parallelism, even if\\nexecuting the program with a low parallelism. Compression # Flink offers optional compression (default: off) for all checkpoints and savepoints. Currently, compression always uses\\nthe snappy compression algorithm (version 1.1.10.x) but we are planning to support\\ncustom compression algorithms in the future. Compression works on the granularity of key-groups in keyed state, i.e.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/large_state_tuning/', 'type': 'document', 'pk': 450143955092273188}),\n",
       " Document(page_content=\"For example, you can easily deploy Flink applications on Kubernetes without Flink knowing that it runs on Kubernetes (and without specifying any of the Kubernetes config options here.) See this setup guide for an example. The options in this section are necessary for setups where Flink itself actively requests and releases resources from the orchestrators. YARN # Key Default Type Description external-resource.<resource_name>.yarn.config-key (none) String If configured, Flink will add this key to the resource profile of container request to Yarn. The value will be set to the value of external-resource.<resource_name>.amount. flink.hadoop.<key> (none) String A general option to probe Hadoop configuration through prefix 'flink.hadoop.'. Flink will remove the prefix to get <key> (from core-default.xml and hdfs-default.xml ) then set the <key> and value to Hadoop configuration. For example, flink.hadoop.dfs.replication=5 in Flink configuration and convert to dfs.replication=5 in Hadoop\", metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/config/', 'type': 'document', 'pk': 450143955092274420}),\n",
       " Document(page_content=\"Application Profiling & Debugging Monitoring â\\x96¾ Monitoring Checkpointing Monitoring Back Pressure Upgrading Applications and Flink Versions Production Readiness Checklist Flink Development â\\x96¾ Importing Flink into an IDE Building Flink from Source Internals â\\x96¾ Jobs and Scheduling Task Lifecycle File Systems Project Homepage JavaDocs ScalaDocs PyDocs Pick Docs Version â\\x96¾ 1.16 (â\\x9c\\x93) v1.16 v1.15 All Versions ä¸\\xadæ\\x96\\x87ç\\x89\\x88 Set up Flink's Process Memory On This Page Configure Total Memory JVM Parameters Capped Fractionated Components Set up Flink’s Process Memory # Apache Flink provides efficient workloads on top of the JVM by tightly controlling the memory usage of its various components.\", metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/memory/mem_setup/', 'type': 'document', 'pk': 450143955092274726})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"How does elastic scaling works in FLink. What are the various configuration used for scaling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/docker/', 'type': 'document', 'pk': 450143955092274102}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/kubernetes/', 'type': 'document', 'pk': 450143955092274178}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/cli/', 'type': 'document', 'pk': 450143955092274966}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/native_kubernetes/', 'type': 'document', 'pk': 450143955092274216}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/kubernetes/', 'type': 'document', 'pk': 450143955092274124}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/docker/', 'type': 'document', 'pk': 450143955092274088}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092273496}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/cli/', 'type': 'document', 'pk': 450143955092274988}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/docker/', 'type': 'document', 'pk': 450143955092274072}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092273518}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/native_kubernetes/', 'type': 'document', 'pk': 450143955092274204}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/kubernetes/', 'type': 'document', 'pk': 450143955092274168}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/overview/', 'type': 'document', 'pk': 450143955092273984}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/docker/', 'type': 'document', 'pk': 450143955092274092}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092273484}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/cli/', 'type': 'document', 'pk': 450143955092274994}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092273556}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/filesystems/gcs/', 'type': 'document', 'pk': 450143955092275260}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/docker/', 'type': 'document', 'pk': 450143955092274104}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/docker/', 'type': 'document', 'pk': 450143955092274068}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/state_backends/', 'type': 'document', 'pk': 450143955092273124}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092273498}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/advanced/logging/', 'type': 'document', 'pk': 450143955092275694}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/kubernetes/', 'type': 'document', 'pk': 450143955092274158}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092273470}\n"
     ]
    }
   ],
   "source": [
    "for doc in retriever.invoke(\"List down all the commands used in the flink documenatation along with explanation of the command.\"):\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "# from langchain_cohere import CohereRerank\n",
    "# compressor = CohereRerank(top_n=5, cohere_api_key=COHERE_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flashrank.Ranker:Downloading ms-marco-MultiBERT-L-12...\n",
      "ms-marco-MultiBERT-L-12.zip: 100%|██████████| 98.7M/98.7M [00:20<00:00, 4.98MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_compressors.flashrank_rerank import FlashrankRerank\n",
    "# from flashrank import Ranker\n",
    "# ranker = Ranker()\n",
    "compressor = FlashrankRerank(top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='parallelism when re-scaling the program (via a savepoint). Flink’s internal bookkeeping tracks parallel state in the granularity of max-parallelism-many key groups .\\nFlink’s design strives to make it efficient to have a very high value for the maximum parallelism, even if\\nexecuting the program with a low parallelism. Compression # Flink offers optional compression (default: off) for all checkpoints and savepoints. Currently, compression always uses\\nthe snappy compression algorithm (version 1.1.10.x) but we are planning to support\\ncustom compression algorithms in the future. Compression works on the granularity of key-groups in keyed state, i.e.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/large_state_tuning/', 'type': 'document', 'pk': 450143955092273188, 'relevance_score': 0.99941087}),\n",
       " Document(page_content='scheduler are also available with it. The Flink community is working on addressing these limitations. No support for the Elastic Scaling . The elastic scaling only supports slot requests without specified-resource at the moment. No support for task manager redundancy . The slotmanager.redundant-taskmanager-num is used to start redundant TaskManagers to speed up job recovery. This config option will not take effect in fine-grained resource management at the moment. No support for evenly spread out slot strategy . This strategy tries to spread out the slots evenly across all available TaskManagers. The strategy is not supported in the first version of fine-grained resource management and cluster.evenly-spread-out-slots will not take effect in it at the moment. Limited integration with Flinkâ\\x80\\x99s Web UI . Slots in fine-grained resource management can have different resource specs. The web UI only shows the slot number without its details at the moment. Limited integration with batch jobs', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/finegrained_resource/', 'type': 'document', 'pk': 450143955092275108, 'relevance_score': 0.9993543}),\n",
       " Document(page_content='Other components can be tuned using multiple options. Framework Memory # You should not change the framework heap memory and framework off-heap memory without a good reason.\\nAdjust them only if you are sure that Flink needs more memory for some internal data structures or operations.\\nIt can be related to a particular deployment environment or job structure, like high parallelism.\\nIn addition, Flink dependencies, such as Hadoop may consume more direct or native memory in certain setups. Note Flink neither isolates heap nor off-heap versions of framework and task memory at the moment.\\nThe separation of framework and task memory can be used in future releases for further optimizations. Local Execution # If you start Flink locally on your machine as a single java program without creating a cluster (e.g. from your IDE)', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/memory/mem_setup_tm/', 'type': 'document', 'pk': 450143955092274780, 'relevance_score': 0.999295}),\n",
       " Document(page_content='While the Flink community has attempted to provide sensible defaults for each configuration, it is important to review this list and ensure the options chosen are sufficient for your needs. Set An Explicit Max Parallelism # The max parallelism, set on a per-job and per-operator granularity, determines the maximum parallelism to which a stateful operator can scale.\\nThere is currently no way to change the maximum parallelism of an operator after a job has started without discarding that operators state.\\nThe reason maximum parallelism exists, versus allowing stateful operators to be infinitely scalable, is that it has some impact on your application’s performance and state size.\\nFlink has to maintain specific metadata for its ability to rescale state which grows linearly with max parallelism.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/production_ready/', 'type': 'document', 'pk': 450143955092273906, 'relevance_score': 0.99920464}),\n",
       " Document(page_content='without putting undue load on your sinks. How much load can your Task Managers sustain: All of Flinks’ built-in state backends support asynchronous checkpointing, meaning the snapshot process will not pause data processing. However, it still does require CPU cycles and network bandwidth from your machines. Incremental checkpointing can be a powerful tool to reduce the cost of any given checkpoint. And most importantly, test and measure your job. Every Flink application is unique, and the best way to find the appropriate checkpoint interval is to see how yours behaves in practice. Configure JobManager High Availability # The JobManager serves as a central coordinator for each Flink deployment, being responsible for both scheduling and resource management of the cluster.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/production_ready/', 'type': 'document', 'pk': 450143955092273914, 'relevance_score': 0.9990993}),\n",
       " Document(page_content='configuration ) { return this ; } } Capacity Planning # This section discusses how to decide how many resources should be used for a Flink job to run reliably.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/large_state_tuning/', 'type': 'document', 'pk': 450143955092273182, 'relevance_score': 0.9990682}),\n",
       " Document(page_content='feature. The Flink community is actively looking for feedback by users through our mailing lists. Please check the limitations listed on this page. Reactive Mode configures a job so that it always uses all resources available in the cluster. Adding a TaskManager will scale up your job, removing resources will scale it down. Flink will manage the parallelism of the job, always setting it to the highest possible values. Reactive Mode restarts a job on a rescaling event, restoring it from the latest completed checkpoint. This means that there is no overhead of creating a savepoint (which is needed for manually rescaling a job). Also, the amount of data that is reprocessed after rescaling depends on the checkpointing interval, and the restore time depends on the state size. The Reactive Mode allows Flink users to implement a powerful autoscaling mechanism, by having an external service monitor certain metrics, such as consumer lag, aggregate CPU utilization, throughput or latency. As soon', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/elastic_scaling/', 'type': 'document', 'pk': 450143955092275032, 'relevance_score': 0.9990302}),\n",
       " Document(page_content='scheduling Tuning Checkpoints and Large State # This page gives a guide how to configure and tune applications that use large state. Overview # For Flink applications to run reliably at large scale, two conditions must be fulfilled: The application needs to be able to take checkpoints reliably The resources need to be sufficient catch up with the input data streams after a failure The first sections discuss how to get well performing checkpoints at scale.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/large_state_tuning/', 'type': 'document', 'pk': 450143955092273160, 'relevance_score': 0.9990053}),\n",
       " Document(page_content='In combination with Kubernetes, the replica count of the TaskManager deployment determines the available resources. Increasing the replica count will scale up the job, reducing it will trigger a scale down. This can also be done automatically by using a Horizontal Pod Autoscaler . To use Reactive Mode on Kubernetes, follow the same steps as for deploying a job using an Application Cluster . But instead of flink-configuration-configmap.yaml use this config map: flink-reactive-mode-configuration-configmap.yaml . It contains the scheduler-mode: reactive setting for Flink. Once you have deployed the Application Cluster , you can scale your job up or down by changing the replica count in the flink-taskmanager deployment. Enabling Local Recovery Across Pod Restarts # In order to speed up recoveries in case of pod failures, you can leverage Flink’s working directory feature together with local recovery.', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/resource-providers/standalone/kubernetes/', 'type': 'document', 'pk': 450143955092274150, 'relevance_score': 0.9989995}),\n",
       " Document(page_content='While the community strives to offer sensible defaults to all configurations, the full breadth of applications\\nthat users deploy on Flink means this isn’t always possible. To provide the most production value to our users,\\nFlink allows both high-level and fine-grained tuning of memory allocation within clusters. To optimize memory requirements, check the network memory tuning guide . The further described memory configuration is applicable starting with the release version 1.10 for TaskManager and 1.11 for JobManager processes. If you upgrade Flink from earlier versions, check the migration guide because many changes were introduced with the 1.10 and 1.11 releases. Configure Total Memory # The total process memory of Flink JVM processes consists of memory consumed by the Flink application ( total Flink memory )', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/memory/mem_setup/', 'type': 'document', 'pk': 450143955092274728, 'relevance_score': 0.9989804})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_retriever.invoke(\"How does elastic scaling works in FLink. What are the various configuration used for scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# from langchain_cohere import ChatCohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatCohere(model=\"command-r-plus\", temperature=0.0, cohere_api_key=COHERE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs: list[Document]):\n",
    "    \n",
    "    text = \"\"\n",
    "\n",
    "    for doc in docs:\n",
    "        xml_tag_start = f\"<{doc.metadata['url'].lower()}>\"\n",
    "        xml_tag_end = f\"</{doc.metadata['url'].lower()}>\"\n",
    "        content = doc.page_content\n",
    "        text += f\"{xml_tag_start}\\n{content}\\n{xml_tag_end}\\n\\n\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_KEY = os.enviorn[\"GEMINI_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=GEMINI_KEY, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "example_prompt = PromptTemplate.from_template(\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.Keep the answer concise and to the point. Write down the citation at the end of the answer that you have taken reference from. The citation names are in form of urls, that are provided in the xml tags.\n",
    "Follow below mention format for citation\n",
    "Citation:\n",
    "        (1) Source URL 1\n",
    "        (2) Source URL 2\n",
    "Only provide citation if you have used the information from the document.\n",
    "Question: {question} \\nContext: {context} \\nAnswer\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_rag = (\n",
    "    {\"context\": compression_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | example_prompt\n",
    "    | google_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      +---------------------------------+              \n",
      "                      | Parallel<context,question>Input |              \n",
      "                      +---------------------------------+              \n",
      "                           ****                  ****                  \n",
      "                       ****                          ****              \n",
      "                     **                                  ****          \n",
      "+--------------------------------+                           **        \n",
      "| ContextualCompressionRetriever |                            *        \n",
      "+--------------------------------+                            *        \n",
      "                 *                                            *        \n",
      "                 *                                            *        \n",
      "                 *                                            *        \n",
      "      +---------------------+                         +-------------+  \n",
      "      | Lambda(format_docs) |                         | Passthrough |  \n",
      "      +---------------------+                        *+-------------+  \n",
      "                           ****                  ****                  \n",
      "                               ****          ****                      \n",
      "                                   **      **                          \n",
      "                     +----------------------------------+              \n",
      "                     | Parallel<context,question>Output |              \n",
      "                     +----------------------------------+              \n",
      "                                       *                               \n",
      "                                       *                               \n",
      "                                       *                               \n",
      "                              +----------------+                       \n",
      "                              | PromptTemplate |                       \n",
      "                              +----------------+                       \n",
      "                                       *                               \n",
      "                                       *                               \n",
      "                                       *                               \n",
      "                          +------------------------+                   \n",
      "                          | ChatGoogleGenerativeAI |                   \n",
      "                          +------------------------+                   \n",
      "                                       *                               \n",
      "                                       *                               \n",
      "                                       *                               \n",
      "                              +-----------------+                      \n",
      "                              | StrOutputParser |                      \n",
      "                              +-----------------+                      \n",
      "                                       *                               \n",
      "                                       *                               \n",
      "                                       *                               \n",
      "                           +-----------------------+                   \n",
      "                           | StrOutputParserOutput |                   \n",
      "                           +-----------------------+                   \n"
     ]
    }
   ],
   "source": [
    "google_rag.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = google_rag.invoke(\"How does elastic scaling works in FLink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Elastic scaling in Flink can be achieved using the Reactive Mode. In this mode, Flink automatically adjusts the parallelism of a job to utilize all available cluster resources. Adding or removing TaskManagers will scale the job up or down, respectively. This mode relies on checkpoints for job restoration during rescaling. Citation:\n",
       ">         (1) https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/elastic_scaling/ \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = google_rag.invoke(\"How does elastic scaling works for the batch job. WHat configuration are needed for scaling the batch job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> The provided text discusses Adaptive Batch Scheduler for parallelism tuning in batch jobs, but it doesn't contain information about elastic scaling for batch jobs. Thus, I cannot answer your question. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = google_rag.invoke(\"How to configure history server. wHat configurations are needed to setup history server on azure?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> To configure the Flink HistoryServer, you need to set the `jobmanager.archive.fs.dir` in `flink-conf.yaml` on the JobManager and `historyserver.archive.fs.dir` on the HistoryServer. The HistoryServer can then monitor the configured directory for archived jobs. Citation:\n",
       "> (1) https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/advanced/historyserver/ \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = google_rag.invoke(\"How to configure flink on azure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> To configure Flink on Azure, you can configure the Azure Blob storage key in the `flink-conf.yaml` file.\n",
       "> Citation:\n",
       ">  (1) https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/deployment/filesystems/azure/ \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/dipak/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 14 files:  43%|████▎     | 6/14 [00:07<00:10,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "from huggingface_hub import snapshot_download\n",
    "os.environ[\"CURL_CA_BUNDLE\"]=\"\"\n",
    "login(token=os.enviorn[\"HF_TOKEN\"])\n",
    "# Hugging Face model identifier\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'  # Replace with your model id\n",
    "\n",
    "\n",
    "# Download model files from Hugging Face\n",
    "model_dir = snapshot_download(repo_id=model_id, ignore_patterns=\"*.bin\")\n",
    "print(f\"Model files downloaded to {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGCHAIN_TRACING_V2=\"true\"\n",
    "LANGCHAIN_API_KEY=os.environ['LANGSMITH_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.weatherapi.com/',\n",
       "  'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1717854186, 'localtime': '2024-06-08 6:43'}, 'current': {'last_updated_epoch': 1717853400, 'last_updated': '2024-06-08 06:30', 'temp_c': 13.3, 'temp_f': 55.9, 'is_day': 1, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/day/122.png', 'code': 1009}, 'wind_mph': 12.5, 'wind_kph': 20.2, 'wind_degree': 240, 'wind_dir': 'WSW', 'pressure_mb': 1012.0, 'pressure_in': 29.88, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 93, 'cloud': 100, 'feelslike_c': 12.0, 'feelslike_f': 53.7, 'windchill_c': 10.4, 'windchill_f': 50.7, 'heatindex_c': 11.9, 'heatindex_f': 53.5, 'dewpoint_c': 10.0, 'dewpoint_f': 49.9, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 4.0, 'gust_mph': 12.6, 'gust_kph': 20.3}}\"},\n",
       " {'url': 'https://world-weather.info/forecast/usa/san_francisco/august-2024/',\n",
       "  'content': 'Extended weather forecast in San Francisco. Hourly Week 10 days 14 days 30 days Year. Detailed ⚡ San Francisco Weather Forecast for August 2024 - day/night 🌡️ temperatures, precipitations - World-Weather.info.'},\n",
       " {'url': 'https://www.weathertab.com/en/d/e/08/united-states/california/san-francisco/',\n",
       "  'content': 'Free Long Range Weather Forecast for San Francisco, California August 2024. Focused Daily Weather, Temperature, Sunrise, Sunset, and Moonphase Forecasts. Enter any city, zip or place. °F °C. Help > United States San Francisco, California ... August 2024 Aug 2024.'},\n",
       " {'url': 'https://www.accuweather.com/en/us/san-francisco/94103/august-weather/347629',\n",
       "  'content': 'Get the monthly weather forecast for San Francisco, CA, including daily high/low, historical averages, to help you plan ahead.'},\n",
       " {'url': 'https://en.climate-data.org/north-america/united-states-of-america/california/san-francisco-385/t/august-8/',\n",
       "  'content': 'Here you can find all information about the weather in San Francisco in August:\\nSan Francisco weather in August\\nSan Francisco weather by month // weather averages\\n9.6\\n(49.2)\\n6.2\\n(43.2)\\n14\\n(57.3)\\n113\\n(4.4)\\n10.5\\n(50.8)\\n7.1\\n(44.8)\\n14.9\\n(58.7)\\n118\\n(4.6)\\n11.6\\n(52.9)\\n8.2\\n(46.8)\\n16.2\\n(61.2)\\n83\\n(3.3)\\n12.5\\n(54.6)\\n8.9\\n(48.1)\\n17.4\\n(63.3)\\n40\\n(1.6)\\n14.1\\n(57.4)\\n10.3\\n(50.6)\\n19.2\\n(66.5)\\n21\\n(0.8)\\n15.9\\n(60.7)\\n11.8\\n(53.3)\\n21.5\\n(70.8)\\n6\\n(0.2)\\n16.3\\n(61.4)\\n12.7\\n(54.9)\\n21.8\\n(71.2)\\n2\\n(0.1)\\n16.7\\n(62.1)\\n13.3\\n(55.9)\\n22.2\\n(71.9)\\n2\\n(0.1)\\n17.1\\n(62.7)\\n13.1\\n(55.6)\\n23.1\\n(73.6)\\n3\\n(0.1)\\n15.7\\n(60.2)\\n11.9\\n(53.4)\\n21.3\\n(70.3)\\n25\\n(1)\\n12.4\\n(54.4)\\n9\\n(48.2)\\n17.1\\n(62.8)\\n57\\n(2.2)\\n9.9\\n(49.8)\\n6.8\\n(44.2)\\n13.9\\n(57.1)\\n111\\n(4.4)\\n9.6 °C\\n(49.2) °F\\n10.5 °C\\n(50.8) °F\\n11.6 °C\\n(52.9) °F\\n12.5 °C\\n(54.6) °F\\n14.1 °C\\n(57.4) °F\\n15.9 °C\\n(60.7) °F\\n16.3 °C\\n(61.4) °F\\n16.7 °C\\n(62.1) °F\\n17.1 °C\\n(62.7) °F\\n15.7 °C\\n(60.2) °F\\n12.4 °C\\n(54.4) °F\\n9.9 °C\\n(49.8) °F\\n6.2 °C\\n(43.2) ° F\\n7.1 °C\\n(44.8) °F\\n8.2 °C\\n(46.8) °F\\n8.9 °C\\n(48.1) °F\\n10.3 °C\\n(50.6) °F\\n11.8 °C\\n(53.3) °F\\n12.7 °C\\n(54.9) °F\\n13.3 °C\\n(55.9) °F\\n13.1 °C\\n(55.6) °F\\n11.9 °C\\n(53.4) °F\\n9 °C\\n(48.2) °F\\n6.8 °C\\n(44.2) °F\\n14 °C\\n(57.3) °F\\n14.9 °C\\n(58.7) °F\\n16.2 °C\\n(61.2) °F\\n17.4 °C\\n(63.3) °F\\n19.2 °C\\n(66.5) °F\\n21.5 °C\\n(70.8) °F\\n21.8 °C\\n(71.2) °F\\n22.2 °C\\n(71.9) °F\\n23.1 °C\\n(73.6) °F\\n21.3 °C\\n(70.3) °F\\n17.1 °C\\n(62.8) °F\\n13.9 °C\\n(57.1) °F\\n113\\n(4)\\n118\\n(4)\\n83\\n(3)\\n40\\n(1)\\n21\\n(0)\\n6\\n(0)\\n2\\n(0)\\n2\\n(0)\\n3\\n(0)\\n25\\n(0)\\n57\\n(2)\\n111\\n(4)\\nData: 1991 - 2021 Min. Temperature °C (°F), Max. London (LHR), Baltimore (BWI), Copenhagen (CPH), Sydney (SYD), Paris (CDG), Toronto (YYZ), Cleveland (CLE), Detroit (DTW), Honolulu (HNL), Beijing (PEK), Dallas (DFW), Calgary (YYC), Frankfurt am Main (FRA), Houston (HOU), New Orleans (MSY), Seattle (SEA), Cancún (CUN), Dubai (DXB), Las Vegas (LAS), Pittsburgh (PIT)\\nSpokane (GEG), Vancouver (YVR), Osaka (KIX), Boise (BOI), New York (JFK), Mexico City (MEX), Orlando (MCO), Salt Lake City (SLC), Phoenix (AZA), Ontario (ONT), Provo (PVU), Albuquerque (ABQ), Denver (DEN), Minneapolis (MSP), St. Louis (STL), Indianapolis (IND), Chicago (MDW), Atlanta (ATL), Cincinnati (CVG), Fort Lauderdale (FLL), Charlotte (CLT), Miami (MIA), Philadelphia (PHL), Washington (IAD), Boston (BOS), Newark (EWR), Manila (MNL), Zurich (ZRH), Tokyo (NRT), Amsterdam (AMS), Morelia (MLM), Auckland (AKL), Montreal (YUL), Shanghai (PVG), Milwaukee (MKE), San Jose Del Cabo (SJD), Taipei City (TPE), Dublin (DUB), Guadalajara (GDL), Portland (PDX), Munich (MUC), Bellingham (BLI), Silao (BJX), Santa Clara (SAL), Eugene (EUG), Los Angeles (LAX), Austin (AUS), San Diego (SAN), Long Beach (LGB), Santa Ana (SNA), Burbank (BUR), Seoul (ICN), Lihue (LIH), Puerto Vallarta (PVR), Palm Springs (PSP), Kansas City (MCI), Hong Kong (HKG), Kahului (OGG)\\nPacifica\\nBroadmoor\\nSausalito\\nMill Valley\\nCorte Madera\\nSan Mateo\\nPalo Alto\\nSan Bruno\\nSouth San Francisco\\nFoster City\\nColma\\nDaly City\\nBrisbane\\nHayward\\nOakland\\nEmeryville\\nTiburon\\nAlbany\\nBerkeley\\nEl Cerrito\\nRichmond\\nNorth Richmond\\nEast Richmond Heights\\nAlameda\\nPiedmont\\nConcord\\nVallejo Sun hours\\nSan Francisco weather and climate for further months\\nSan Francisco weather in August // weather averages\\nAirport close to San Francisco\\n Temperature °C (°F), Precipitation / Rainfall mm (in), Humidity, Rainy days.\\n'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"what is the weather in SF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"output\": \"Welcome to LangSmith\"},        {\"output\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(    lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here    data=dataset_name, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"how to upload a dataset\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mGet started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "Skip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith​PythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key​To create an API key head to the Settings page. Then click Create API Key.3. Set up your environment​Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace​We provide multiple ways to log traces to LangSmith. Below, we'll highlight\n",
      "\n",
      "score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\n",
      "\n",
      "\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform that can help with testing by allowing you to closely monitor and evaluate your application. It enables you to build production-grade LLM (Large Language Model) applications, ensuring that you can ship your products quickly and with confidence. Here are some ways LangSmith can assist with testing:\n",
      "\n",
      "1. **Installation**: You can install LangSmith using Python or TypeScript by running the appropriate commands.\n",
      "2. **Create an API Key**: Generate an API key in the Settings page to authenticate and interact with LangSmith.\n",
      "3. **Environment Setup**: Set up your environment variables to configure LangSmith for your specific needs.\n",
      "4. **Logging Traces**: LangSmith provides multiple methods to log traces, which are essential for monitoring and evaluating your application during testing.\n",
      "5. **Evaluation**: You can run evaluations on your test cases using LangSmith, ensuring that your application meets the desired criteria.\n",
      "\n",
      "By utilizing LangSmith, you can streamline your testing process and ensure the reliability and quality of your applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': 'LangSmith is a platform that can help with testing by allowing you to closely monitor and evaluate your application. It enables you to build production-grade LLM (Large Language Model) applications, ensuring that you can ship your products quickly and with confidence. Here are some ways LangSmith can assist with testing:\\n\\n1. **Installation**: You can install LangSmith using Python or TypeScript by running the appropriate commands.\\n2. **Create an API Key**: Generate an API key in the Settings page to authenticate and interact with LangSmith.\\n3. **Environment Setup**: Set up your environment variables to configure LangSmith for your specific needs.\\n4. **Logging Traces**: LangSmith provides multiple methods to log traces, which are essential for monitoring and evaluating your application during testing.\\n5. **Evaluation**: You can run evaluations on your test cases using LangSmith, ensuring that your application meets the desired criteria.\\n\\nBy utilizing LangSmith, you can streamline your testing process and ensure the reliability and quality of your applications.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.nws.noaa.gov/wtf/MapClick.php?CityName=San+Francisco&state=CA&site=MTR&textField1=37.775&textField2=-122.418&e=0&lg=ep', 'content': 'San Francisco CA. NWS. Point Forecast: San Francisco CA. 37.77°N 122.41°W. Mobile Weather Information | En Español. Last Update: 1:59 pm PDT May 14, 2024. Forecast Valid: 4pm PDT May 14, 2024-6pm PDT May 21, 2024.'}, {'url': 'https://www.accuweather.com/en/us/san-francisco/94103/weather-forecast/347629', 'content': 'Get the current and future weather conditions for San Francisco, CA, including temperature, precipitation, wind, air quality and more. See the hourly and 10-day outlook, radar maps, alerts and allergy information.'}, {'url': 'https://www.accuweather.com/en/us/san-francisco/94103/weather-forecast/6-347629_1_al', 'content': 'Get the current weather, air quality, and health and activities information for San Francisco, CA. See the hourly, daily, and monthly forecasts, as well as radar maps and severe weather alerts.'}, {'url': 'https://weather.com/weather/tenday/l/San Francisco CA USCA0987:1:US', 'content': \"Comfy & Cozy\\nThat's Not What Was Expected\\nOutside\\n'No-Name Storms' In Florida\\nGifts From On High\\nWhat To Do For Wheezing\\nSurviving The Season\\nStay Safe\\nAir Quality Index\\nAir quality is considered satisfactory, and air pollution poses little or no risk.\\n Health & Activities\\nSeasonal Allergies and Pollen Count Forecast\\nNo pollen detected in your area\\nCold & Flu Forecast\\nFlu risk is low in your area\\nWe recognize our responsibility to use data and technology for good. recents\\nSpecialty Forecasts\\n10 Day Weather-San Francisco, CA\\nToday\\nMon 18 | Day\\nConsiderable cloudiness. Tue 19\\nTue 19 | Day\\nLight rain early...then remaining cloudy with showers in the afternoon. Wed 27\\nWed 27 | Day\\nOvercast with rain showers at times.\"}, {'url': 'https://forecast.weather.gov/zipcity.php?inputstring=San+Francisco,CA', 'content': 'Severe weather, mainly hail and wind, and flash flood potential will extend from the central High Plains, through southern Kansas into the middle Mississippi and lower Ohio Valleys. ... San Francisco CA 37.77°N 122.41°W (Elev. 131 ft) Last Update: 6:00 pm PDT Jun 7, 2024. Forecast Valid: 7pm PDT Jun 7, 2024-6pm PDT Jun 14, 2024 .'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in San Francisco is currently around 37.77°N 122.41°W. You can find more detailed and up-to-date information on the [National Weather Service website](https://www.nws.noaa.gov/wtf/MapClick.php?CityName=San+Francisco&state=CA&site=MTR&textField1=37.775&textField2=-122.418&e=0&lg=ep).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in sf?',\n",
       " 'output': 'The weather in San Francisco is currently around 37.77°N 122.41°W. You can find more detailed and up-to-date information on the [National Weather Service website](https://www.nws.noaa.gov/wtf/MapClick.php?CityName=San+Francisco&state=CA&site=MTR&textField1=37.775&textField2=-122.418&e=0&lg=ep).'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
