{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere.embeddings import CohereEmbeddings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: Alibaba-NLP/gte-large-en-v1.5\n",
      "/Users/dipak/FlinkBot/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
    "model_kwargs = {'device': 'mps', \"trust_remote_code\": True}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MILVUS_URL = os.environ['MILVUS_URL']\n",
    "MILVUS_KEY = os.environ['MILVUS_URL']\n",
    "DIMS = 1024\n",
    "EMBEDDING_MODEL = \"embed-english-v3.0\"\n",
    "COHERE_KEY=os.environ['COHERE_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_fn = CohereEmbeddings(model=EMBEDDING_MODEL, cohere_api_key=COHERE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = hf.embed_query(\"What is flink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.zilliz import Zilliz\n",
    "\n",
    "zilliz = Zilliz(\n",
    "    embedding_function = hf,\n",
    "    collection_name=\"FlinkNEW\",\n",
    "    connection_args={\"uri\": MILVUS_URL, \"token\": MILVUS_KEY},\n",
    "    auto_id=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = zilliz.as_retriever(search_kwargs={\"k\": 25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092270970}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092270992}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092270958}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092271030}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/state_backends/', 'type': 'document', 'pk': 450143955092270598}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/state_backends/#incremental-checkpoints', 'type': 'document', 'pk': 450143955092272290}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/state_backends/#timers-heap-vs-rocksdb', 'type': 'document', 'pk': 450143955092272382}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/state_backends/#memory-management', 'type': 'document', 'pk': 450143955092272474}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/state_backends/#choose-the-right-state-backend', 'type': 'document', 'pk': 450143955092272870}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092270972}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092270944}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092271094}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092271036}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092270974}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092270988}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092271084}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092270902}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092270980}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092271038}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/savepoints/', 'type': 'document', 'pk': 450143955092270486}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/savepoints/#resuming-from-savepoints', 'type': 'document', 'pk': 450143955092271430}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/savepoints/#savepoint-format', 'type': 'document', 'pk': 450143955092271544}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092270990}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/', 'type': 'document', 'pk': 450143955092270962}\n",
      "{'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/batch/batch_shuffle/', 'type': 'document', 'pk': 450143955092271130}\n"
     ]
    }
   ],
   "source": [
    "for doc in retriever.invoke(\"List down all the commands used in the flink documenatation along with explanation of the command.\"):\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "# from langchain_cohere import CohereRerank\n",
    "# compressor = CohereRerank(top_n=5, cohere_api_key=COHERE_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_compressors.flashrank_rerank import FlashrankRerank\n",
    "# from flashrank import Ranker\n",
    "# ranker = Ranker()\n",
    "compressor = FlashrankRerank(top_n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='is that Flink might immediately build an incremental checkpoint on top of the restored one. Therefore,', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/savepoints/', 'type': 'document', 'pk': 450143955092270490, 'relevance_score': 0.99825484}),\n",
       " Document(page_content='is that Flink might immediately build an incremental checkpoint on top of the restored one. Therefore,', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/savepoints/#resuming-from-savepoints', 'type': 'document', 'pk': 450143955092271434, 'relevance_score': 0.99825484}),\n",
       " Document(page_content='is that Flink might immediately build an incremental checkpoint on top of the restored one. Therefore,', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/savepoints/#savepoint-format', 'type': 'document', 'pk': 450143955092271548, 'relevance_score': 0.99825484}),\n",
       " Document(page_content='or in-flight record types for the existing operators have changed. Non-arbitrary job upgrade - restoring the snapshot is possible with updated operators if the job graph topology and in-flight record types remain unchanged. Flink minor version upgrade - restoring a snapshot taken with an older minor version of Flink (1.x â\\x86\\x92 1.y). Flink bug/patch version upgrade - restoring a snapshot taken with an older patch version of Flink (1.14.x â\\x86\\x92 1.14.y). Rescaling - restoring the snapshot with a different parallelism than was used during the snapshot creation. Back to top Want to contribute translation? Edit This Page On This Page Overview Capabilities and limitations', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/checkpoints_vs_savepoints/', 'type': 'document', 'pk': 450143955092270526, 'relevance_score': 0.99386847}),\n",
       " Document(page_content='workaround is to store the watermark in the operator state. In that case, watermarks should be\\nstored per key group in a union state to support rescaling. Interplay with long-running record processing # Despite that unaligned checkpoints barriers are able to overtake all other records in the queue.\\nThe handling of this barrier still can be delayed if the current record takes a lot of time to be processed.\\nThis situation can occur when firing many timers all at once, for example in windowed operations.\\nSecond problematic scenario might occur when system is being blocked waiting for more than one\\nnetwork buffer availability when processing a single input record. Flink can not interrupt processing of\\na single input record, and unaligned checkpoints have to wait for the currently processed record to be\\nfully processed. This can cause problems in two scenarios. Either as a result of serialisation of a large', metadata={'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/checkpointing_under_backpressure/', 'type': 'document', 'pk': 450143955092270436, 'relevance_score': 0.98958445})]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_retriever.invoke(\"What is flink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# from langchain_cohere import ChatCohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatCohere(model=\"command-r-plus\", temperature=0.0, cohere_api_key=COHERE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs: list[Document]):\n",
    "    \n",
    "    text = \"\"\n",
    "\n",
    "    for doc in docs:\n",
    "        xml_tag_start = f\"<{doc.metadata['url'].lower()}>\"\n",
    "        xml_tag_end = f\"</{doc.metadata['url'].lower()}>\"\n",
    "        content = doc.page_content\n",
    "        text += f\"{xml_tag_start}\\n{content}\\n{xml_tag_end}\\n\\n\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_KEY = \"AIzaSyBVI2jAHepUzLwWoK6qwXCOYxD0NFzZIns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=GEMINI_KEY, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "example_prompt = PromptTemplate.from_template(\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.Keep the answer concise and to the point. Write down the citation at the end of the answer that you have taken reference from. The citation names are in form of urls, that are provided in the xml tags.\n",
    "Follow below mention format for citation\n",
    "Citation:\n",
    "        (1) Source URL 1\n",
    "        (2) Source URL 2\n",
    "Only provide citation if you have used the information from the document.\n",
    "Question: {question} \\nContext: {context} \\nAnswer\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_rag = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | example_prompt\n",
    "    | google_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              +---------------------------------+           \n",
      "              | Parallel<context,question>Input |           \n",
      "              +---------------------------------+           \n",
      "                    ****                ****                \n",
      "                 ***                        ***             \n",
      "               **                              ***          \n",
      "+----------------------+                          **        \n",
      "| VectorStoreRetriever |                           *        \n",
      "+----------------------+                           *        \n",
      "            *                                      *        \n",
      "            *                                      *        \n",
      "            *                                      *        \n",
      "+---------------------+                     +-------------+ \n",
      "| Lambda(format_docs) |                     | Passthrough | \n",
      "+---------------------+                     +-------------+ \n",
      "                    ****                ****                \n",
      "                        ***          ***                    \n",
      "                           **      **                       \n",
      "              +----------------------------------+          \n",
      "              | Parallel<context,question>Output |          \n",
      "              +----------------------------------+          \n",
      "                                *                           \n",
      "                                *                           \n",
      "                                *                           \n",
      "                      +----------------+                    \n",
      "                      | PromptTemplate |                    \n",
      "                      +----------------+                    \n",
      "                                *                           \n",
      "                                *                           \n",
      "                                *                           \n",
      "                  +------------------------+                \n",
      "                  | ChatGoogleGenerativeAI |                \n",
      "                  +------------------------+                \n",
      "                                *                           \n",
      "                                *                           \n",
      "                                *                           \n",
      "                      +-----------------+                   \n",
      "                      | StrOutputParser |                   \n",
      "                      +-----------------+                   \n",
      "                                *                           \n",
      "                                *                           \n",
      "                                *                           \n",
      "                   +-----------------------+                \n",
      "                   | StrOutputParserOutput |                \n",
      "                   +-----------------------+                \n"
     ]
    }
   ],
   "source": [
    "google_rag.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = google_rag.invoke(\"List down all the commands used in the flink documenatation along with explanation of the command.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> This document does not contain the answer to this question. It provides information about the structure of the JSON objects used in the Flink REST API. It does not list or explain any Flink commands. Citation: \n",
       ">         (1) https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/\n",
       ">         (2) https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/rest_api/"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = google_rag.invoke(\"How to handle backpressure situations. WHat options are available.List down each of the configueration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> To handle backpressure situations in Flink, you have three options:\n",
       "> \n",
       "> 1. **Remove the backpressure source:** Optimize the Flink job, adjust Flink or JVM configurations, or scale up resources.\n",
       "> 2. **Reduce buffered in-flight data:** Use techniques like buffer debloating to control the amount of data being held in buffers.\n",
       "> 3. **Enable unaligned checkpoints:** This allows checkpoint barriers to progress faster, even under backpressure, but it's important to understand its trade-offs. \n",
       "> \n",
       "> Citation:\n",
       ">         (1) https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/checkpointing_under_backpressure/ \n",
       ">         (2) https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/checkpointing_under_backpressure/#unaligned-checkpoints \n",
       ">         (3) https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/checkpointing_under_backpressure/#buffer-debloating \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
